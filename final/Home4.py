# -*- coding: utf-8 -*-
"""app.py (Added PM2.5 vs Health Tab)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JD0ExI29iyq8JATPMFQpEKF88jlYBxgL
"""

# app.py (Added PM2.5 vs Health Tab using OLS/GLM)

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.ensemble import RandomForestRegressor
import numpy as np
import traceback
from pymongo import MongoClient, errors as mongo_errors
from datetime import datetime
import statsmodels.api as sm # Import statsmodels

# --- Configuration & Caching ---
st.set_page_config(layout="wide", page_title="NYC Air Quality & Health Analysis")

# --- Constants ---
MONGO_URI = "mongodb://localhost:27017/" # Change if needed
DB_NAME = "nyc_health_air_quality"
POLLUTANT_COLLECTIONS = ['boiler', 'pm25', 'no2', 'o3']
HEALTH_COLLECTIONS = ['asthma', 'resp']
VALUE_COL_MAP = {
    'boiler': 'boiler_emissions', 'pm25': 'PM25', 'no2': 'NO2', 'o3': 'O3',
    'asthma': 'asthma_rate', 'resp': 'respiratory_rate'
}
POLLUTANT_DISPLAY_NAMES = {
    'boiler_emissions': 'Boiler Emissions (SO₂)', 'PM25': 'PM₂.₅',
    'NO2': 'Nitrogen Dioxide (NO₂)', 'O3': 'Ozone (O₃)'
}

# --- Initialize Session State ---
# (Session state initialization remains the same)
if 'current_view' not in st.session_state:
    st.session_state.current_view = 'filters'
if 'selected_location' not in st.session_state: st.session_state.selected_location = None
if 'start_date' not in st.session_state: st.session_state.start_date = None
if 'end_date' not in st.session_state: st.session_state.end_date = None
if 'selected_pollutants' not in st.session_state: st.session_state.selected_pollutants = []
if 'selected_health_outcome_label' not in st.session_state: st.session_state.selected_health_outcome_label = None
if 'selected_health_outcome_col' not in st.session_state: st.session_state.selected_health_outcome_col = None


# --- MongoDB Connection ---
@st.cache_resource
def get_mongo_db():
    # (Function remains the same)
    try:
        client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
        client.admin.command('ping')
        db = client[DB_NAME]
        print("MongoDB connection successful.")
        return db
    except mongo_errors.ConnectionFailure as e:
        st.error(f"MongoDB Connection Error: Could not connect to server at {MONGO_URI}.")
        st.error(f"Details: {e}")
        return None
    except Exception as e:
        st.error(f"An unexpected error during MongoDB connection: {e}")
        return None

# --- Data Loading from MongoDB ---
@st.cache_data
def load_data_from_mongo(_db_conn, collection_name):
    # (Function remains the same)
    if _db_conn is None: return pd.DataFrame()
    try:
        collection = _db_conn[collection_name]
        value_col = VALUE_COL_MAP.get(collection_name)
        if not value_col: return pd.DataFrame(columns=['geo_place_name', 'date'])
        projection = {'_id': 0, 'geo_place_name': 1, 'date': 1, value_col: 1}
        data = list(collection.find({}, projection))
        if not data: return pd.DataFrame(columns=['geo_place_name', 'date', value_col])
        df = pd.DataFrame(data)
        df['date'] = pd.to_datetime(df['date'])
        if value_col not in df.columns: pass
        return df
    except Exception as e:
        st.error(f"Error loading '{collection_name}': {e}")
        return pd.DataFrame(columns=['geo_place_name', 'date', VALUE_COL_MAP.get(collection_name, 'value')])

# --- Data Loading for Health Outcome Analysis Tab ---
@st.cache_data # Cache this specific dataset load
def load_cleaned_health_data(file_path='data/cleaned_health_outcome.csv'):
    """Loads the pre-cleaned health outcome vs PM2.5 data."""
    try:
        df = pd.read_csv(file_path)
        required = ["PM2.5", "AsthmaRate", "RespiratoryRate"]
        if not all(col in df.columns for col in required):
            st.error(f"Error: File '{file_path}' is missing required columns: {required}")
            return None
        print(f"Loaded '{file_path}' for PM2.5 Health Analysis tab.")
        return df
    except FileNotFoundError:
        st.error(f"Error: Required file '{file_path}' not found in the main project directory.")
        return None
    except Exception as e:
        st.error(f"An error occurred loading data: {e}")
        return None

# --- Modified Preprocessing Function ---
@st.cache_data
def preprocess_mongo_data(dataframes_dict):
    """Merges, creates grid, interpolates, and prepares modeling data."""
    # (Preprocessing logic remains the same as the previous version)
    # ... (Ensure it returns: final_df, X_model, y_asthma_model, y_resp_model) ...
    if not dataframes_dict: return None, None, None, None
    essential_collections = POLLUTANT_COLLECTIONS + HEALTH_COLLECTIONS
    if all(name not in dataframes_dict or dataframes_dict[name] is None or dataframes_dict[name].empty for name in essential_collections):
        st.error("Preprocessing failed: Essential data sources empty/missing.")
        return None, None, None, None
    try:
        all_places = set()
        min_date, max_date = pd.Timestamp.max, pd.Timestamp.min
        valid_dfs_exist = False
        for df in dataframes_dict.values():
            if df is not None and not df.empty:
                valid_dfs_exist = True
                if 'geo_place_name' in df.columns: all_places.update(df['geo_place_name'].unique())
                if 'date' in df.columns:
                    min_date = min(min_date, df['date'].min())
                    max_date = max(max_date, df['date'].max())
        if not valid_dfs_exist or not all_places or min_date > max_date: return None, None, None, None
        all_places = sorted(list(all_places))
        all_dates_monthly = pd.period_range(start=min_date, end=max_date, freq='M').strftime('%Y-%m')
        full_grid = pd.MultiIndex.from_product([all_places, all_dates_monthly], names=["geo_place_name", "YearMonth"]).to_frame(index=False)
        merged_data = full_grid.copy()
        pollutant_cols_found = []
        for coll_name in POLLUTANT_COLLECTIONS:
            if coll_name in dataframes_dict and dataframes_dict[coll_name] is not None and not dataframes_dict[coll_name].empty:
                df = dataframes_dict[coll_name].copy()
                value_col = VALUE_COL_MAP[coll_name]
                if value_col not in df.columns: continue
                df['YearMonth'] = df['date'].dt.to_period('M').astype(str)
                if 'geo_place_name' in df.columns and 'YearMonth' in df.columns:
                    df_monthly = df.groupby(['geo_place_name', 'YearMonth'], as_index=False)[value_col].mean()
                    merged_data = pd.merge(merged_data, df_monthly, on=["geo_place_name", "YearMonth"], how="left")
                    pollutant_cols_found.append(value_col)
        merged_data['Date_temp'] = pd.to_datetime(merged_data['YearMonth'], errors='coerce')
        merged_data = merged_data.dropna(subset=['Date_temp'])
        interpolated_pollutants = []
        for place, group in merged_data.groupby("geo_place_name"):
            group = group.sort_values("Date_temp").copy()
            for col in pollutant_cols_found:
                if col in group.columns:
                    group[col] = pd.to_numeric(group[col], errors='coerce')
                    try:
                        group_indexed = group.set_index('Date_temp')
                        group[col] = group_indexed[col].interpolate(method='time', limit_direction='both').values
                    except (ValueError, TypeError): group[col] = group[col].interpolate(method='linear', limit_direction='both')
            interpolated_pollutants.append(group)
        if not interpolated_pollutants: return None, None, None, None
        merged_interpolated = pd.concat(interpolated_pollutants, ignore_index=True)
        merged_interpolated['Year'] = merged_interpolated['Date_temp'].dt.year
        final_df = merged_interpolated.copy()
        health_cols_found = []
        for coll_name in HEALTH_COLLECTIONS:
             if coll_name in dataframes_dict and dataframes_dict[coll_name] is not None and not dataframes_dict[coll_name].empty:
                 df_health = dataframes_dict[coll_name].copy()
                 value_col_health = VALUE_COL_MAP[coll_name]
                 if value_col_health not in df_health.columns: continue
                 df_health['Year'] = df_health['date'].dt.year
                 if 'geo_place_name' in df_health.columns and 'Year' in df_health.columns:
                     df_health[value_col_health] = pd.to_numeric(df_health[value_col_health], errors='coerce')
                     health_avg = df_health.groupby(['geo_place_name', 'Year'], as_index=False)[value_col_health].mean()
                     final_df = pd.merge(final_df, health_avg, on=['geo_place_name', 'Year'], how='left')
                     health_cols_found.append(value_col_health)
        final_df = final_df.drop(columns=['Date_temp'])
        if pollutant_cols_found: final_df = final_df.dropna(subset=pollutant_cols_found, how='all')
        cols_for_model_avg = pollutant_cols_found + health_cols_found
        cols_for_model_avg = [col for col in cols_for_model_avg if col in final_df.columns]
        if not cols_for_model_avg: return final_df, pd.DataFrame(), pd.Series(dtype=float), pd.Series(dtype=float)
        model_data = final_df.groupby('geo_place_name', as_index=False)[cols_for_model_avg].mean()
        model_data = model_data.dropna(subset=cols_for_model_avg, how='any')
        X_model_cols = [p for p in pollutant_cols_found if p in model_data.columns]
        if not model_data.empty and X_model_cols:
             X_model = model_data.set_index('geo_place_name')[X_model_cols]
             y_asthma_model = model_data.set_index('geo_place_name')['asthma_rate'] if 'asthma_rate' in health_cols_found and 'asthma_rate' in model_data.columns else pd.Series(dtype=float)
             y_resp_model = model_data.set_index('geo_place_name')['respiratory_rate'] if 'respiratory_rate' in health_cols_found and 'respiratory_rate' in model_data.columns else pd.Series(dtype=float)
        else: X_model, y_asthma_model, y_resp_model = pd.DataFrame(columns=pollutant_cols_found), pd.Series(dtype=float), pd.Series(dtype=float)
        final_df = final_df.rename(columns={'geo_place_name': 'Geo Place Name'})
        return final_df, X_model, y_asthma_model, y_resp_model
    except Exception as e:
        st.error(f"Error during preprocessing: {e}")
        st.error(traceback.format_exc())
        return None, None, None, None


# --- Load data from MongoDB ---
with st.spinner("Connecting to database and loading data..."):
    db = get_mongo_db()
    dataframes = {}
    if db is not None:
        all_collections = POLLUTANT_COLLECTIONS + HEALTH_COLLECTIONS
        for collection_name in all_collections:
            dataframes[collection_name] = load_data_from_mongo(db, collection_name)
    # Preprocess Data
    final_data, X_model_data, y_asthma_model_data, y_resp_model_data = preprocess_mongo_data(dataframes)

# --- Train Models ---
with st.spinner("Training prediction models..."):
    # (Model training logic remains the same)
    model_asthma = None
    model_resp = None
    trained_features = []
    if X_model_data is not None and not X_model_data.empty:
        trained_features = X_model_data.columns.tolist()
        if y_asthma_model_data is not None and not y_asthma_model_data.empty and len(X_model_data) == len(y_asthma_model_data):
            try:
                model_asthma = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10)
                model_asthma.fit(X_model_data, y_asthma_model_data)
            except Exception as e: model_asthma = None
        if y_resp_model_data is not None and not y_resp_model_data.empty and len(X_model_data) == len(y_resp_model_data):
            try:
                model_resp = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10)
                model_resp.fit(X_model_data, y_resp_model_data)
            except Exception as e: model_resp = None


# --- Function to Display Filter View ---
def display_filter_view(available_pollutants_list):
    # (Filter view function remains the same as previous version with help text)
    left_spacer, content_col, right_spacer = st.columns([1, 2, 1])
    with content_col:
        st.markdown("Select options below and click 'Analyze'.")
        st.header("🔍 Select Analysis Filters")
        with st.container(border=True):
            if final_data is not None and not final_data.empty:
                locations = sorted(final_data['Geo Place Name'].unique())
                loc_key = "loc_filter_main"
                default_loc_name = st.session_state.get(loc_key)
                loc_index = 0
                if default_loc_name and default_loc_name in locations:
                    try: loc_index = locations.index(default_loc_name)
                    except ValueError: loc_index = locations.index('NYC') if 'NYC' in locations else 0
                elif 'NYC' in locations: loc_index = locations.index('NYC')
                selected_location = st.selectbox(
                    "**Location:**", options=locations, index=loc_index, key=loc_key,
                    label_visibility="collapsed", help="Select the geographic area for analysis."
                )
                st.markdown("**Date Range**")
                date_cols = st.columns(2)
                with date_cols[0]:
                    min_date_dt = pd.to_datetime(final_data['YearMonth'].min()).to_pydatetime() if 'YearMonth' in final_data.columns and final_data['YearMonth'].min() else datetime(2005,1,1)
                    max_date_dt = pd.to_datetime(final_data['YearMonth'].max()).to_pydatetime() if 'YearMonth' in final_data.columns and final_data['YearMonth'].max() else datetime.now()
                    start_date_key = "start_date_main"
                    start_date_default = st.session_state.get(start_date_key, min_date_dt)
                    start_date = st.date_input(
                        "Start Date:", min_value=min_date_dt, max_value=max_date_dt, value=start_date_default, key=start_date_key,
                        label_visibility="visible", help="Select the beginning of the date range."
                    )
                with date_cols[1]:
                    end_date_key = "end_date_main"
                    end_date_default = st.session_state.get(end_date_key, max_date_dt)
                    end_date = st.date_input(
                        "End Date:", min_value=min_date_dt, max_value=max_date_dt, value=end_date_default, key=end_date_key,
                        label_visibility="visible", help="Select the end of the date range."
                    )
                st.markdown("---")
                st.markdown("**Pollutants**")
                pollutant_key = "pollutant_main"
                pollutant_default = st.session_state.get(pollutant_key, available_pollutants_list[:2])
                selected_pollutants = st.multiselect(
                    "Select Pollutants:", options=available_pollutants_list,
                    default=pollutant_default, key=pollutant_key,
                    format_func=lambda x: POLLUTANT_DISPLAY_NAMES.get(x, x),
                    label_visibility="collapsed", help="Select one or more pollutants."
                )
                st.markdown("**Health Outcome (for Prediction)**")
                health_outcomes = {'Asthma ED Visits Rate': 'asthma_rate', 'Respiratory Hospitalization Rate (Age 20+)': 'respiratory_rate'}
                health_labels = list(health_outcomes.keys())
                health_key = "health_main"
                default_health_label = st.session_state.get(health_key, health_labels[0])
                health_index = health_labels.index(default_health_label) if default_health_label in health_labels else 0
                selected_health_outcome_label = st.radio(
                    "Select Health Outcome:", options=health_labels,
                    index=health_index, horizontal=True, key=health_key,
                    label_visibility="collapsed", help="Select the health outcome for the prediction model."
                )
                selected_health_outcome_col = health_outcomes[selected_health_outcome_label]
                st.markdown("---")
                _, btn_col, _ = st.columns([1, 1, 1])
                with btn_col:
                    if st.button("🚀 Analyze Data", type="primary", use_container_width=True):
                        st.session_state.selected_location = selected_location
                        st.session_state.start_date = start_date
                        st.session_state.end_date = end_date
                        st.session_state.selected_pollutants = selected_pollutants
                        st.session_state.selected_health_outcome_label = selected_health_outcome_label
                        st.session_state.selected_health_outcome_col = selected_health_outcome_col
                        st.session_state.current_view = 'results'
                        st.rerun()
            else:
                 st.error("Data could not be loaded or preprocessed from MongoDB. Cannot display filters.")


# --- Function to Display Results View ---
def display_results_view(available_pollutants_list):
    sel_loc = st.session_state.selected_location
    sel_start_date = st.session_state.start_date
    sel_end_date = st.session_state.end_date
    sel_pollutants = st.session_state.selected_pollutants
    sel_health_label = st.session_state.selected_health_outcome_label
    sel_health_col = st.session_state.selected_health_outcome_col

    if st.button("⬅️ Back to Filters"):
        st.session_state.current_view = 'filters'
        st.rerun()

    st.header(f"📊 Analysis Results for: {sel_loc}")
    start_ym = pd.Timestamp(sel_start_date).to_period("M").strftime('%Y-%m')
    end_ym = pd.Timestamp(sel_end_date).to_period("M").strftime('%Y-%m')
    st.markdown(f"**Date Range:** {start_ym} to {end_ym}")
    st.markdown("---")

    with st.spinner("Filtering data..."):
        # (Filtering logic remains the same)
        filtered_by_location = final_data[final_data['Geo Place Name'] == sel_loc].copy()
        if not filtered_by_location.empty:
            filtered_by_location['Date_temp'] = pd.to_datetime(filtered_by_location['YearMonth']).dt.to_period('M')
            start_period = pd.Period(start_ym, freq='M')
            end_period = pd.Period(end_ym, freq='M')
            filtered_by_date = filtered_by_location[
                (filtered_by_location['Date_temp'] >= start_period) &
                (filtered_by_location['Date_temp'] <= end_period)
            ].copy()
            if not filtered_by_date.empty:
                 filtered_by_date['Date_plot'] = filtered_by_date['Date_temp'].dt.to_timestamp()
            else: filtered_by_date = pd.DataFrame()
        else: filtered_by_date = pd.DataFrame()

    if filtered_by_date.empty and not filtered_by_location.empty: st.warning(f"No data for {sel_loc} in range.", icon="⚠️")
    elif filtered_by_location.empty: st.warning(f"No data for {sel_loc}.", icon="⚠️")

    # --- Use Tabs for Different Analysis Sections ---
    # MODIFIED: Removed the second tab title "🔗 Relationships"
    tab_titles = ["📈 Trends", "📈 Regression", # Removed "🔗 Relationships"
                  f"⚕️ Prediction ({sel_health_label})", "🩺 PM2.5 vs Health (OLS/GLM)"]
    # MODIFIED: Removed the variable 'tab2'
    tab1, tab3, tab4, tab5 = st.tabs(tab_titles) # Removed tab2

    # --- Tab 1: Trends ---
    with tab1:
        # (Code remains the same as previous version with Plotly)
        st.subheader("Pollutant Trends Over Time")
        if not filtered_by_date.empty and sel_pollutants:
            with st.spinner("Generating trends plot..."):
                try:
                    plot_data_trends = filtered_by_date.sort_values('Date_plot')
                    plot_data_melted = plot_data_trends.melt(id_vars=['Date_plot'], value_vars=sel_pollutants, var_name='Pollutant', value_name='Value')
                    plot_data_melted['Pollutant'] = plot_data_melted['Pollutant'].map(POLLUTANT_DISPLAY_NAMES)
                    fig_trends = px.line(plot_data_melted, x='Date_plot', y='Value', color='Pollutant', markers=True, title=f"Pollutant Levels in {sel_loc}", labels={'Date_plot': 'Date', 'Value': 'Concentration / Emission Level'})
                    fig_trends.update_layout(legend_title_text='Pollutant')
                    st.plotly_chart(fig_trends, use_container_width=True)
                except Exception as e: st.error(f"Could not generate trends plot: {e}")
        elif not sel_pollutants: st.info("Select pollutants to display trends.")
        else: st.info(f"No trend data available for {sel_loc} in range.")

    # --- DELETED Tab 2: Relationships ---
    # The entire 'with tab2:' block has been removed.

    # --- Tab 3: Regression --- (Now assigned to the second tab position)
    with tab3: # This block now corresponds to the second visible tab
        st.subheader("📈 Interactive Regression Analysis")

        # Create column mapping for display (ensure this is defined earlier)
        pollutant_display_names = {
            'boiler_emissions': 'Boiler Emissions',
            'PM25': 'PM₂.₅', # Using subscript characters for better display
            'NO2': 'NO₂',
            'O3': 'O₃'
            # Add other pollutants if needed
        }
        # Ensure 'available_pollutants' list is defined earlier in your scope
        # Example: available_pollutants = ['boiler_emissions', 'PM25', 'NO2', 'O3']

        # Column selectors for regression
        col1, col2 = st.columns(2)
        with col1:
            # Use a unique key for the selectbox if this code might appear multiple times
            x_pollutant = st.selectbox(
                "Select X-axis Pollutant:",
                options=available_pollutants,
                format_func=lambda x: pollutant_display_names.get(x, x),
                index=0,
                key="reg_x_select" # Added a key for robustness
            )
        with col2:
            # Use a unique key for the selectbox
            y_pollutant = st.selectbox(
                "Select Y-axis Pollutant:",
                options=available_pollutants,
                format_func=lambda x: pollutant_display_names.get(x, x),
                index=1 if len(available_pollutants) > 1 else 0,
                key="reg_y_select" # Added a key for robustness
            )

        # Check if same variables are selected
        if x_pollutant == y_pollutant:
            st.warning("Please select two **different** pollutants for X and Y axes.")
        else:
            # Ensure 'filtered_by_location' DataFrame is defined earlier
            # Example: filtered_by_location = final_data[final_data['Geo Place Name'] == sel_loc].copy()

            # Prepare data for regression
            reg_data = filtered_by_location[[x_pollutant, y_pollutant]].dropna()

            if not reg_data.empty and len(reg_data) > 1: # Need at least 2 points for regression
                try:
                    # --- Create Plotly Express regression plot ---
                    fig_reg = px.scatter(
                        reg_data,
                        x=x_pollutant,
                        y=y_pollutant,
                        trendline="ols",  # Add Ordinary Least Squares trendline
                        trendline_color_override="red", # Match the example image color
                        labels={ # Use display names for labels
                            x_pollutant: pollutant_display_names.get(x_pollutant, x_pollutant),
                            y_pollutant: pollutant_display_names.get(y_pollutant, y_pollutant)
                        },
                        title=f"Regression: {pollutant_display_names.get(y_pollutant, y_pollutant)} vs {pollutant_display_names.get(x_pollutant, x_pollutant)}"
                    )

                    # Optional: Customize marker appearance if needed
                    fig_reg.update_traces(marker=dict(size=8, opacity=0.6)) # Slightly larger markers

                    # Display the Plotly chart
                    st.plotly_chart(fig_reg, use_container_width=True)

                    # --- Calculate and display correlation coefficient ---
                    corr = reg_data.corr().iloc[0, 1]
                    # Use st.metric for a nicer display, similar to the image's info box
                    st.metric(label="Correlation coefficient (r)", value=f"{corr:.3f}")
                    # Alternatively, use st.info like before:
                    # st.info(f"Correlation coefficient (r): {corr:.3f}")

                except Exception as e:
                    st.error(f"Could not generate regression plot: {e}")
                    st.error(traceback.format_exc()) # Show detailed error in console/log

            else:
                # Ensure 'selected_location' variable is defined earlier
                # Example: selected_location = st.session_state.selected_location
                st.warning(
                    f"Insufficient overlapping data available for regression analysis between "
                    f"'{pollutant_display_names.get(x_pollutant, x_pollutant)}' and "
                    f"'{pollutant_display_names.get(y_pollutant, y_pollutant)}' in {selected_location}."
                )

    # --- Tab 4: Prediction ---
    with tab4:
        # (Code remains the same as previous version with Plotly)
        st.subheader(f"Health Outcome Prediction")
        st.markdown(f"Predicting average **{sel_health_label}** for **{sel_loc}** based on its average pollutant levels.")
        with st.spinner("Generating prediction..."):
            location_avg_data = X_model_data.loc[[sel_loc]] if X_model_data is not None and sel_loc in X_model_data.index else None
            model_to_use = model_asthma if sel_health_col == 'asthma_rate' else model_resp
            actual_value = None
            if sel_health_col == 'asthma_rate' and y_asthma_model_data is not None and sel_loc in y_asthma_model_data.index: actual_value = y_asthma_model_data.loc[sel_loc]
            elif sel_health_col == 'respiratory_rate' and y_resp_model_data is not None and sel_loc in y_resp_model_data.index: actual_value = y_resp_model_data.loc[sel_loc]
            if model_to_use is not None and location_avg_data is not None and not location_avg_data.empty:
                try:
                    location_avg_data_aligned = location_avg_data.reindex(columns=trained_features, fill_value=0)
                    prediction = model_to_use.predict(location_avg_data_aligned)[0]
                    pred_col, actual_col = st.columns(2)
                    with pred_col: st.metric(label=f"Predicted Avg. Rate", value=f"{prediction:.2f}")
                    with actual_col:
                        if actual_value is not None and not np.isnan(actual_value): st.metric(label=f"Actual Avg. Rate", value=f"{actual_value:.2f}", delta=f"{prediction - actual_value:.2f}", delta_color="off")
                        else: st.info(f"Actual average data not available.")
                    st.markdown("---")
                    if hasattr(model_to_use, 'feature_importances_'):
                        st.markdown("**Pollutant Importance for Prediction**")
                        display_feature_names = [POLLUTANT_DISPLAY_NAMES.get(f, f) for f in trained_features]
                        importance_df = pd.DataFrame({'Feature': display_feature_names,'Importance': model_to_use.feature_importances_}).sort_values(by='Importance', ascending=False).reset_index(drop=True)
                        fig_imp = px.bar(importance_df, x='Importance', y='Feature', orientation='h', title=f"Pollutant Importance for Predicting {sel_health_label}", labels={'Importance': 'Importance Score', 'Feature': 'Pollutant'}, color='Importance', color_continuous_scale=px.colors.sequential.Viridis)
                        fig_imp.update_layout(yaxis={'categoryorder':'total ascending'}, height=max(300, len(trained_features)*40))
                        st.plotly_chart(fig_imp, use_container_width=True)
                        with st.expander("View Importance Scores"):
                             raw_importance_df = pd.DataFrame({'Feature': trained_features,'Importance': model_to_use.feature_importances_}).sort_values(by='Importance', ascending=False)
                             st.dataframe(raw_importance_df.style.format({'Importance': "{:.3f}"}))
                except Exception as pred_err: st.error(f"Prediction failed: {pred_err}")
            elif model_to_use is None: st.error(f"Model for {sel_health_label} is unavailable.")
            else: st.warning(f"Avg pollutant data not available for {sel_loc}.", icon="⚠️")

    # --- NEW Tab 5: PM2.5 vs Health (OLS/GLM) ---
    with tab5:
        st.subheader("Specific Analysis: PM₂.₅ vs Health Outcomes")
        st.markdown("This analysis uses the cleaned, aggregated dataset (`cleaned_health_outcome.csv`) focusing specifically on PM₂.₅.")

        # Load the specific cleaned data for this tab
        with st.spinner("Loading cleaned health data..."):
            df_health_tab = load_cleaned_health_data()

        if df_health_tab is None or df_health_tab.empty:
            st.error("Could not load 'cleaned_health_outcome.csv' for this analysis.")
        else:
            # Radio button to choose outcome within this tab
            outcome_choice_tab5 = st.radio(
                "Select Health Outcome for PM₂.₅ Regression:",
                ("Asthma ED Visits Rate", "Respiratory Hospitalization Rate (Age 20+)"),
                key="tab5_outcome_select", # Unique key
                horizontal=True
            )
            outcome_col_map_tab5 = {
                "Asthma ED Visits Rate": "AsthmaRate",
                "Respiratory Hospitalization Rate (Age 20+)": "RespiratoryRate"
            }
            selected_col_tab5 = outcome_col_map_tab5[outcome_choice_tab5]

            # Prepare data
            if selected_col_tab5 not in df_health_tab.columns or "PM2.5" not in df_health_tab.columns:
                 st.error(f"Required columns ('PM2.5', '{selected_col_tab5}') not found in cleaned data.")
            else:
                df_reg_tab5 = df_health_tab[["PM2.5", selected_col_tab5]].dropna()
                if len(df_reg_tab5) < 2:
                     st.warning(f"Not enough data points to run regression for {outcome_choice_tab5}.")
                else:
                    y_tab5 = df_reg_tab5[selected_col_tab5]
                    X_tab5 = sm.add_constant(df_reg_tab5["PM2.5"])

                    # Run and display analysis
                    with st.spinner(f"Running PM₂.₅ regression for {outcome_choice_tab5}..."):
                        try:
                            # OLS Model
                            ols_model_tab5 = sm.OLS(y_tab5, X_tab5).fit()
                            with st.expander("View OLS Regression Summary"):
                                st.text(ols_model_tab5.summary())

                            # GLM Model (for plot consistency, though results similar to OLS for Gaussian)
                            glm_model_tab5 = sm.GLM(y_tab5, X_tab5, family=sm.families.Gaussian()).fit()
                            # with st.expander("View GLM Regression Summary"): # Optional: uncomment to show GLM too
                            #     st.text(glm_model_tab5.summary())

                            # Plot using Plotly
                            st.markdown("**Regression Plot**")
                            fig_glm_tab5 = px.scatter(
                                df_reg_tab5, x="PM2.5", y=selected_col_tab5,
                                trendline="ols", trendline_color_override="green", # Use OLS trendline from Plotly
                                title=f"PM₂.₅ vs {outcome_choice_tab5}",
                                labels={"PM2.5": "PM₂.₅ Concentration", selected_col_tab5: outcome_choice_tab5}
                            )
                            fig_glm_tab5.update_traces(marker=dict(size=5, opacity=0.6))
                            st.plotly_chart(fig_glm_tab5, use_container_width=True)

                        except Exception as e:
                            st.error(f"Failed regression analysis for {outcome_choice_tab5}: {e}")


# --- Main App Logic ---
st.title("🏙️ NYC Air Quality and Health Outcome Analysis")

if db is not None:
    # Define available_pollutants after data processing
    if final_data is not None:
        available_pollutants = trained_features if trained_features else [col for col in VALUE_COL_MAP.values() if col in final_data.columns and col not in ['asthma_rate', 'respiratory_rate']]
    else:
        available_pollutants = []

    # Display the appropriate view
    if st.session_state.current_view == 'filters':
        display_filter_view(available_pollutants)
    elif st.session_state.current_view == 'results':
        if final_data is not None and not final_data.empty:
            display_results_view(available_pollutants)
        else:
             st.error("Data is not available to display results.")
             if st.button("⬅️ Back to Filters"):
                 st.session_state.current_view = 'filters'
                 st.rerun()
    else: # Reset if state is invalid
        st.session_state.current_view = 'filters'
        st.rerun()
else:
    st.error("Failed to establish connection with the database. Please ensure MongoDB is running.")


# --- Footer Info (Sidebar) ---
st.sidebar.markdown("---")
st.sidebar.info("App based on NYC Open Data for air quality and health indicators.")
